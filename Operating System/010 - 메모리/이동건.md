# 메모리

## 메인 메모리

> 메인 메모리는 **거대한 바이트의 배열**이며 각 바이트에는 **주소(address)**가 지정된다!
> 

**메인 메모리**와 각 처리 코어에 내장된 **레지스터**들은 CPU가 **직접 접근할 수 있는 유일한 범용 저장장치**이다. 따라서 **모든 실행되는 명령어와 데이터들은** CPU가 직접 접근할 수 있는 메인 메모리와 레지스터에 있어야 한다.

각 CPU 코어에 내장된 레지스터들은 일반적으로 CPU 클럭의 1 사이클 내에 접근이 가능하다. 하지만 메모리 버스를 통해 전송되는 메인 메모리의 경우 많은 CPU 사이클을 소모하게 된며 이럴 경우 CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연되는 현상이 발생한다. 메인 메모리의 접근이 빈번하지만 지연되는 상황이 발생하면 안되므로 CPU와 메인 메모리 사이에 **캐시** 라는 빠른 메모리를 둔다.

---

### 캐시

> 메인메모리에 저장된 내용의 일부를 임시로 저장해두는 기억장치
> 

CPU와 캐시가 상호작용하는 방법은 다음과 같다.

1) HIT (존재) : 해당 명령어를 CPU로 전송한다.

2) Miss (비존재) : 명령어를 가지고 메인 메모리에 접근하여 해당 명령어를 가진 데이터를 꺼내서 캐시에 저장한   후 CPU로 전송한다.

---

### 지역성의 원리

**적중률 (Hit rate)**를 높이기 위해서 지역성의 원리를 사용한다. 지역성 (Locality)란 기억 장치 내의 정보를 균일하게 Access하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 성질이 있다는 이론이다.

- 시간 지역성 (Temporal Locality): 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성
- 공간 지역성 (Spatial Locality): 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

물리 메모리의 상대적인 접근 속도 차이는 캐시를 통해 해결하였다. 추가적으로 시스템이 올바르게 작동하기 위해서는 운영체제가 사용자 프로그램 사이의 영역을 보호 해야 한다.

---

## MMU (Memory Management Unit)

> 메모리 관리의 핵심적인 역할을 담당한다!
> 

CPU가 생성하는 주소를 일반적으로 논리주소라 하는데 논리주소에서 물리주소로 변환하는 역할을 한다.
![Untitled](https://user-images.githubusercontent.com/70252417/209144680-60e617c5-5e87-439d-90b3-a0ac98d7adef.png)


메모리의 공간이 한정적이기 때문에 사용자에게 더 많은 메모리 공간을 제공하고자 **가상 메모리** 라는 개념이 등장했다. 이 가상 메모리의 논리 주소를 가지고 실제 데이터가 담겨있는 메인 메모리에 빠르게 접근 하기 위해서는 빠른 주소 변환이 필요하며 이를 **MMU**가 해준다.

![Untitled 1](https://user-images.githubusercontent.com/70252417/209144703-6ccebf9b-1133-4260-af7b-2f80f8fdb00d.png)

- 장점
    - 모든 프로세스마다 같은 주소를 사용할 수 있게 해준다.
        
        실제 물리주소가 다 다르더라도 MMU는 가상 주소로 이를 모두 하나로 표현할 수 있다.
        
    - 서로 떨어져 있는 데이터여도 연속된 데이터로 표현될 수 있다.
        
        실제 물리주소가 13, 25, 39 와 같이 떨어져 있어도 연속된 데이터처럼 1, 2, 3 처럼 표현 할 수 있다.
        

---

## 가상 메모리

> 메모리를 관리하는 방법으로 실제 메모리 주소가 아닌 **논리적 주소**를 이용해서 관리
> 

실제로 이용 가능한 자원을 이상적으로 추상화하여 사용자들에게 매우 큰 메모리로 보이게 만드는 것
![Untitled 2](https://user-images.githubusercontent.com/70252417/209144725-40fd22cc-2bd4-482b-975a-73b728204d88.png)


프로그램의 일부만 실제로 적재함으로써 즉, **실제로 프로그램 수행에 필요한 부분만 메모리에 올려놓음**으로써 **주 기억장치의 용량보다 큰 프로그램 파일이라도** 사용자가 메모리에 올려놓을 수 있게 만드는 기법이다. Secondary Memory가 메인 메모리 일부처럼 사용할 수 있도록 address가 지정될 수 있는 스토리지 할당 방식이다.

- 가상 주소 공간을 통해 논리적으로 연속성을 가지게 된다.
- Translation에 의해 매핑 되므로 실제 물리적 주소에 대해 알 필요가 없다.

---

## MMU의 메모리 보호

프로세스는 **독립적인 메모리 공간**을 가져야하고, **자신의 공간만 접근**해야 한다. 따라서 MMU는 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호한다.

**base**와 **limit** 레지스터를 활용한 메모리 보호!

![Untitled 3](https://user-images.githubusercontent.com/70252417/209144754-7962a40f-c3e5-45e5-baa4-89bf1ec083f4.png)
![Untitled 4](https://user-images.githubusercontent.com/70252417/209144771-cea5a19d-59ee-4e7c-9a52-e2568e2dc250.png)


base 레지스터는 **프로세스의 시작주소를 물리 주소**로 저장하고 limit 레지스터는 **프로세스의 사이즈**를 저장한다. 즉 **프로세스의 접근 가능한 합법적인 메모리 영역**은 $base <= x < base +limit$ 이 된다. MMU는 동적으로 가상 주소에 base 레지스터 값을 더함으로써 주소를 변환하는 역할을 한다.

CPU 스케줄러가 다음으로 수행할 프로세스를 선택할 때, **디스패처는 문맥 교환(context switching)의 일환으로 base 레지스터와 limit 레지스터에 정확한 값을 적재**한다. CPU에 의해서 생성되는 모든 주소는 **위의 레지스터들의 값을 참조해서 확인 작업을 거치기 때문에** 다른 사용자의 프로그램을 현재 수행 중인 사용자 프로그램의 접근으로부터 보호할 수 있다.

---

## 메모리 할당 - 연속할당

> 각각의 프로세스가 메모리의 연속적인 공간에 적재
> 

### 1. 고정 분할 방식

고정 분할 방식은 물리적 메모리를 주어진 개수만큼 영구적인 분할로 미리 나누어두고 각 분할에 하나의 프로세스를 적재해 실행 시킬 수 있게 하는 것이다. 분할의 크기는 모두 동일하게 할 수도 서로 다르게 할 수도 있다.
![Untitled 5](https://user-images.githubusercontent.com/70252417/209144788-2d5e0b44-ed4a-4397-a848-df297f3d48e0.png)


고정 분할 방식은 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되어 있으며 수행 가능한 프로그램의 최대 크기도 정해져 있다. 또한 고정 분할 방식은 내부 단편화와 모두 발생할 수 있다.
![Untitled 6](https://user-images.githubusercontent.com/70252417/209144837-a1913341-75dd-4401-83df-68415ea3b337.png)


### 2. 가변분할 방식

가변 분할 방식은 고정 분할 방식과 달리 **메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식**을 말한다.
![Untitled 7](https://user-images.githubusercontent.com/70252417/209144877-ba510784-399b-476a-b48a-2b371592fd99.png)


분할의 크기를 프로그램의 크기에 맞게 할당하기 때문에 **내부 단편화는 발생하지 않지만** **외부 단편화가 발생**하게 된다. 이러한 외부 단편화를 해결하기 위한 방법은 다음과 같다

- First Fit : 프로세스를 메모리의 빈공간에 배치할 때 메모리에서 적재 가능한 공간을 순서대로 찾다가 첫 번째로 발견한 공간에 배치
- Best Fit : 메모리의 빈 공간을 모두 확인한 후 적당한 크기 가운데 가장 작은 공간에 프로세스 배치
- Next Fit : 맨 마지막으로 할당된 곳 이후를 스캔하고 다음으로 할당 가능한 곳을 할당한다.

---

## 메모리 할당 - 불연속 할당

> 하나의 프로세스가 불연속적인 주소공간에 분산되어 할당 될 수 있다.
> 
1. 단순 페이징
2. 단순 세그멘테이션
3. **가상 메모리 페이징**
    
    단순 페이징과 비교해서 프로세스 페이지 전부를 메인 메모리에 로드시킬 필요가 없다.
    
    필요한 페이지가 있으면 나중에 자동으로 불러들어지며 외부 단편화가 없다.
    
4. **가상 메모리 세그멘테이션**
    
    필요하지 않은 세그멘트들은 로드되지 않는다.
    
    필요한 세그멘트 있을 때 나중에 자동으로 불러들여지며 내부 단편화가 없다.
    

3, 4는 하지만 복잡한 메모리 관리로 오버헤드가 발생한다.

---

## 메모리 과할당

> 실제 메모리의 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황
> 

페이징 기법과 같은 메모리 기법은 사용자가 큰 메모리를 사용하는 것처럼 느끼도록 눈속임을 통해 메모리를 할당 해 준다. 하지만 **과할당 상황에서는 사용자를 속인 것을 들킬만한 상황이 존재**한다.

프로세스 실행 도중 페이지 폴트가 발생하면 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾는다. 이 때, 메모리의 빈 프레임에 페이지를 올려야 하는데 **모든 메모리가 사용중이라 빈 프레임이 없는 상황이 발생**한다.

이러한 과할당을 해결 하기 위한 방법으로 다음 두 가지가 거론될 수 있다.

1. 메모리에 올라와 있는 한 프로세스를 종료시켜 빈 프레임을 얻는다.
2. 프로세스 하나를 **swap out** 하고 **이 공간을 빈 프레임으로 활용**한다.

1번 방법은 프로세스가 하나 종료되므로 사용자에게 이러한 페이징 시스템이 들킬 가능성이 매우 높다.

> 페이징 기법은 사용자 모르게 시스템 능률을 높이기 위해 선택한 일이므로 들키지 않게 처리해야 한다.
> 

따라서 2번과 같은 **페이지 교체**가 이루어 져야 한다.

---

## 페이지 교체

> 페이지를 swap out 해서 빈 프레임을 확보하는 것
> 

![Untitled 8](https://user-images.githubusercontent.com/70252417/209144909-8d714bdb-8ee0-4658-a0f2-04cc84db8e0c.png)

1. 프로세스 실행 도중 페이지 부재 발생
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾는다.
3. 메모리에 빈 프레임이 있는지 확인
    - 빈 프레임이 있으면 해당 프레임을 사용
    - 빈 프레임이 없으면, victim 프레임을 선정해 디스크에 기록하고 페이지 테이블을 업데이트한다.
    
    > victim frame은 현재 자신이 차지하고 있는 Frame을 **지금 당장 실행해야 할 페이지에게 넘겨줄 프레임**이다.
    > 
4. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고, 페이지 테이블 업데이트한다.

페이지 교체가 이루어지면 아무일이 없던것 처럼 프로세스를 계속 수행시켜주면서 사용자가 알지 못하도록 해야한다. 이 때, 아무일도 일어나지 않은 것처럼 하려면 페이지 **교체 당시 오버헤드를 최대한 줄여야 한다.**

### 접근 횟수를 아예 줄이기

swapping 과정에서 디스크의 접근이 총 두 번 이루어 진다. 모든 페이지에 변경 사항이 있는지 여부를 판단하는 비트를 둔다. victim 페이지가 정해지면 해당 비트를 확인한다.

- 해당 bit가 set 상태 : 페이지의 내용이 달라졌으므로 디스크에 기록해야 한다.
- 해당 bit가 clear 상태 : 페이지 내용이 달라지지 않았으므로 디스크에 접근 하지 않아도 된다.

### 페이지 교체 알고리즘

페이지 교체 알고리즘을 상황에 따라 잘 사용하면 오버헤드를 줄일 수 있다. 즉, 현재 상황에서 페이지 폴트 확률을 최대한 줄여 줄 수 있는 알고리즘을 사용해야 한다.
